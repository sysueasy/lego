# 2. Process Management

## What is process?

Informally, a process is a program in execution. The status of the current activity of a process is represented by the value of the **program counter** and the contents of the **processor’s registers**. The memory layout of a process is typically divided into multiple sections, and is shown in Figure.

![](../.gitbook/assets/screen-shot-2018-08-09-at-16.26.42.png)

* **Text** section—the executable code
* **Data** section—global variables
* **Heap** section—memory that is dynamically allocated during program run time
* **Stack** section—temporary data storage when invoking functions \(such as function parameters, return addresses, and local variables\)

The sizes of the text and data sections are fixed, as their sizes do not change during program run time. The stack and heap sections can shrink and grow dynamically during program execution. 

The figure shown below illustrates the layout of a C program in memory:

![](../.gitbook/assets/screen-shot-2018-07-09-at-16.36.18%20%281%29.png)

Each time a function is called, an **activation record** containing function parameters, local variables, and the return address is **pushed** onto the stack; when control is returned from the function, the activation record is **popped** from the stack. Similarly, the heap will grow as memory is dynamically allocated, and will shrink when memory is returned to the system. Although the stack and heap sections grow **toward** one another, the operating system must ensure they do not **overlap** one another.

A program is a _passive_ entity, such as a file containing a list of instructions stored on disk \(often called an **executable file**\). A program becomes a process when an executable file is loaded into memory.

As a process executes, it changes **state**. A process may be in one of the following states: new, running, waiting, ready, terminated. It is important to realize that only one process can be **running** on any processor core at any instant.

Each process is represented in the operating system by a **process control block** \(**PCB**\)—also called a task control block. On systems that support **multi-threads**, the PCB is expanded to include information for each thread. PCB simply serves as the repository for all the data needed to start, or restart, a process, along with some accounting data.

## Process Scheduling

The objective of multiprogramming is to have some process running at all times so as to maximize CPU utilization. The objective of time sharing is to switch a CPU core among processes so frequently that users can interact with each program while it is running. To meet these objectives, the **process scheduler** selects an available process \(possibly from a set of several available processes\) for program execution on a core. The number of processes currently in memory is known as the **degree of multiprogramming**.

As processes enter the system, they are put into a **ready queue**, where they are ready and waiting to execute on a CPU’s core. This queue is generally stored as a linked list. Processes that are waiting for a certain event to occur — such as completion of I/O — are placed in a **wait queue**.

![](../.gitbook/assets/screen-shot-2018-08-09-at-17.10.36.png)

A common representation of process scheduling is a queueing diagram: the ready queue and a set of wait queues.

![](../.gitbook/assets/screen-shot-2018-08-09-at-17.08.08.png)

A process migrates among the ready queue and various wait queues throughout its lifetime. The role of the **CPU scheduler** is to select from among the processes that are in the ready queue and allocate a CPU core to one of them.

Some operating systems have an intermediate form of scheduling, known as **swapping**, whose key idea is that sometimes it can be advantageous to remove a process from memory \(and from active contention for the CPU\) and thus reduce the degree of multiprogramming. Later, the process can be reintroduced into memory, and its execution can be continued where it left off.

As mentioned, [interrupts](1.-introduction.md#interrupt) cause the operating system to change a CPU core from its current task and to run a kernel routine. Such operations happen frequently on general-purpose systems. When an interrupt occurs, the system needs to **save** the current context of the process running on the CPU core so that it can **restore** that context when its processing is done.

Switching the CPU core to another process requires performing a state save of the current process and a state restore of a different process. This task is known as a **context switch**.

![](../.gitbook/assets/screen-shot-2018-08-09-at-17.41.25.png)

When a context switch occurs, the kernel saves the context of the old process in its PCB and loads the saved context of the new process scheduled to run. Context-switch time is pure overhead, because the system does no useful work while switching. Switching speed varies from machine to machine, a typical speed is a several microseconds\( $$1/10^6$$s \). 

{% hint style="info" %}
Early versions of iOS did not provide user-application multitasking; only one user application ran in the foreground. Operating- system tasks were multitasked because they were written by Apple and well behaved.

However, beginning with iOS 4, Apple provided a limited form of multitasking for user applications, thus allowing a single foreground application to run concurrently with multiple background applications. \(On a mobile device, the foreground application is the application currently open and appearing on the display. The background application remains in memory, but does not occupy the display screen.\)

[Subsequent versions](https://developer.apple.com/library/archive/releasenotes/General/WhatsNewIniOS/Introduction/Introduction.html) of iOS began to support richer functionality for multi-tasking with fewer restrictions. For example, the larger screen on iPad tablets allowed running two foreground apps at the same time, a technique known as split-screen.

Since its origins, Android has supported multitasking and does not place constraints on the types of applications that can run in the background. If an application requires processing while in the background, the application must use a **service**, a separate application component that runs on behalf of the background process.
{% endhint %}

## Process Operations

During the course of execution, a process may create several new processes. As mentioned earlier, the creating process is called a parent process, and the new processes are called the children of that process. Each of these new processes may in turn create other processes, forming a **tree of processes**.

Most operating systems \(including UNIX, Linux, and Windows\) identify processes according to a unique **process identifie** \(or **pid**\), which is typically an integer number.

Cooperating processes require an **interprocess communication** \(IPC\) mechanism that will allow them to exchange data. There are two fundamental models of IPC: **shared memory** and **message passing**. Both are common.

