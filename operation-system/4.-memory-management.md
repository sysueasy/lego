# 3. Memory Management

## Main Memory

Memory consists of a large array of bytes, each with its own address. A typical instruction-execution cycle, for example, first fetches an instruction from memory. The instruction is then decoded and may cause operands to be fetched from memory. After the instruction has been executed, results may be stored back in memory.

**Main memory** and the **registers** are the only general-purpose storage that the CPU can access directly. Registers are generally accessible within one cycle of the CPU clock. Completing a memory access may take many cycles of the CPU clock.

We first need to make sure that each process has a separate memory space. We can provide this protection by using two registers, the **base register** holds the smallest legal physical memory address; the **limit register** specifies the size of the range.![](https://blobscdn.gitbook.com/v0/b/gitbook-28427.appspot.com/o/assets%2F-LBZ0bpd0aCrMSE1AsyI%2F-LJltkn-cfD2TP4jsKhh%2F-LJlzQxUoT9O1jwmk5HD%2FScreen%20Shot%202018-08-13%20at%2014.33.42.png?alt=media&token=ffe4bcac-bc07-4a47-96e0-e64c4dd78830)

**Address Binding**: Addresses in the source program are generally symbolic \(such as the variable _count_\). A compiler typically binds these symbolic addresses to relocatable addresses \(such as “14 bytes from the beginning of this module”\). The linker or loader in turn binds the relocatable addresses to absolute addresses \(such as 74014\). Each binding is a mapping from one address space to another.

Classically, the binding of instructions and data to memory addresses can be done at any step along the way:

* Compile time: If you know at compile time where the process will reside in memory, then **absolute code** can be generated.
* Load time: If it is not known at compile time where the process will reside in memory, then the compiler must generate **relocatable code**. In this case, final binding is delayed until load time.
* **Execution time**: If the process can be moved during its execution from one memory segment to another, then binding must be delayed until run time. _**Most operating systems use this method**_.

An address generated by the CPU is commonly referred to as a **logical address**, whereas an address seen by the memory unit—that is, the one loaded into the memory-address register of the memory—is commonly referred to as a **physical address**.

Binding addresses at either compile or load time generates identical logical and physical addresses. However, the execution-time address-binding scheme results in differing logical and physical addresses. In this case, we usually refer to the logical address as a **virtual address**. We use logical address and virtual address interchangeably in this text. The set of all logical addresses generated by a program is a **logical address space**. The set of all physical addresses corresponding to these logical addresses is a **physical address space**. Thus, in the execution-time address-binding scheme, the logical and physical address spaces differ.

We now have two different types of addresses: logical addresses \(in the range \[ _0_, _max_ \]\) and physical addresses \(in the range \[ _R+0, R+max_ \] for a base value _R_ \). The run-time mapping from virtual to physical addresses is done by a hardware device called the memory-management unit \(MMU\).![](https://blobscdn.gitbook.com/v0/b/gitbook-28427.appspot.com/o/assets%2F-LBZ0bpd0aCrMSE1AsyI%2F-LJltkn-cfD2TP4jsKhh%2F-LJm1mTzSCVy4jdJr1r7%2FScreen%20Shot%202018-08-13%20at%2014.48.13.png?alt=media&token=7dee976f-713d-48ef-a0b1-1bbf7ae93b7e)

To obtain better memory-space utilization, we can use **dynamic loading**. The main program is loaded into memory and is executed. Other routines are loaded only when they are needed. In such a situation, although the total program size may be large, the portion that is used \(and hence loaded\) may be much smaller.

**Dynamically linked libraries** \(DLLs\) are system libraries that are linked to user programs when the programs are run. **Dynamic linking**, in contrast, is similar to dynamic loading. Here, though, linking, rather than loading, is postponed until execution time. This feature is usually used with system libraries, such as the standard C language library. Without this facility, each program on a system must include a copy of its language library \(or at least the routines referenced by the program\) in the executable image. A second advantage of DLLs is that these libraries can be shared among multiple processes, so that only one instance of the DLL in main memory. For this reason, DLLs are also known as shared libraries, and are used extensively in Windows and Linux systems.

The memory is usually divided into two partitions: one for the operating system and one for the user processes. Most operating systems place the operating system in high memory address.

## Paging {#paging}

Paging is a memory-management scheme that permits a process’s physical address space to be non-contiguous. The basic method for implementing paging involves breaking physical memory into fixed-sized blocks called **frames** and breaking logical memory into blocks of the same size called **pages**. When a process is to be executed, its pages are loaded into any available memory frames from their source.

Every address generated by the CPU is divided into two parts: a **page number** \(p\) and a **page offset** \(d\). The page number is used as an index into a per-process **page table**. The page table contains the base address of each frame in physical memory, and the offset is the location in the frame being referenced.![](https://blobscdn.gitbook.com/v0/b/gitbook-28427.appspot.com/o/assets%2F-LBZ0bpd0aCrMSE1AsyI%2F-LJmHc1FDqVVh9tWcg04%2F-LJmHo5pZ8QOMfd-HG2m%2FScreen%20Shot%202018-08-13%20at%2015.58.15.png?alt=media&token=79827572-4e87-481d-89dc-158a0ab0f578)

The page size \(like the frame size\) is defined by the hardware. For instance, on x86-64 systems, Windows 10 supports page sizes of 4 KB and 2 MB. Linux also supports two page sizes: a default page size \(typically 4 KB\) and an architecture-dependent larger page size called **huge pages**.

```text
// OBTAINING THE PAGE SIZE ON LINUX SYSTEMSgetconfig PAGESIZE
```

The programmer views memory as one single space, containing only this one program. In fact, the user program is scattered throughout physical memory, which also holds other programs. The logical addresses are translated into physical addresses. This map- ping is hidden from the programmer and is controlled by the operating system.

Since the operating system is managing physical memory, it must be aware of the allocation details of physical memory—which frames are allocated, which frames are available, how many total frames there are, and so on. This information is generally kept in a single, system-wide data structure called a **frame table**.

## Swapping {#swapping}

A process, or a portion of a process, can be **swapped** temporarily out of memory to a **backing store** and then brought back into memory for continued execution. A **page out** operation moves a page from memory to the backing store; the reverse process is known as a **page in**.

Instead of using swapping, when free memory falls below a certain threshold, Apple’s iOS asks applications to voluntarily relinquish allocated memory. Applications that fail to free up sufficient memory may be terminated by the operating system. Android adopts a similar strategy, it may terminate a process if insufficient free memory is available. However, before terminating a process, Android writes its application state to flash memory so that it can be quickly restarted.

## Virtual Memory

Virtual memory is a technique that allows the execution of processes that are not completely in memory. This separation allows an extremely large virtual memory to be provided for programmers when only a smaller physical memory is available.

The **virtual address space** of a process refers to the logical \(or virtual\) view of how a process is stored in memory. Typically, this view is that a process begins at a certain logical address—say, address 0—and exists in contiguous memory. Though, that in fact physical memory is organized in page frames that may not be contiguous. It is up to the memory-management unit \(MMU\) to map logical pages to physical page frames in memory.

Recall that the [stack and heap sections grow toward one another](2.-process-management.md#what-is-process), the operating system must ensure they do not overlap one another. The large blank space \(or **hole**\) between the heap and the stack is part of the virtual address space but will require actual physical pages only if the heap or stack grows.

### Demand Paging

The instructions being executed must be in physical memory. The first approach to meeting this requirement is to place the entire logical address space in physical memory. In fact, in many cases, the entire program is not needed. For instance:

* Code to handle unusual error conditions which seldom, if ever, occur in practice.
* Arrays, lists, and tables are often allocated more memory than they actually need.
* Certain options and features of a program may be used rarely.

Even in those cases where the entire program is needed, it may not all be needed at the same time.

An alternative strategy is to load pages only as they are needed, known as **demand paging** and is commonly used in virtual memory systems.

While a process is executing, some pages will be in memory, and some will be in secondary storage. The valid– invalid bit scheme can be used for this purpose. When the bit is set to “_valid_,” the associated page is both legal and in memory. If the bit is set to “_invalid_,” the page either is not valid \(that is, not in the logical address space of the process\) or is valid but is currently in secondary storage.

![](../.gitbook/assets/screen-shot-2018-08-14-at-17.23.18.png)

Access to a page marked invalid causes a **page fault**. The paging hardware, in translating the address through the page table, will notice that the invalid bit is set, causing a **trap** to the operating system.

![](../.gitbook/assets/screen-shot-2018-08-14-at-17.56.06.png)

The hardware to support demand paging is the same as the hardware for paging and swapping:

* Page table. This table has the ability to mark an entry invalid through a valid–invalid bit or a special value of protection bits. 
* Secondary memory. The secondary memory is usually a high-speed disk or NVM device. It is known as the swap device, and the section of storage used for this purpose is known as **swap space**.



